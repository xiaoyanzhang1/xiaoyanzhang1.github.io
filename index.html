<!doctype html>
<html lang="en">

<head>
  <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css"
        integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/all.min.css" integrity="sha512-xh6O/CkQoPOWDdYTDqeRdPCVd1SpvCA9XXcUnZS2FmJNp1coAFzvtCN9BmamE+4aHK8yyUHUSCcJHgXloTyT2A==" crossorigin="anonymous" referrerpolicy="no-referrer" />

    <title>Xiaoyan Zhang</title>
    <link rel="icon" type="image/x-icon" href="assets/goose.ico">
  
    <script>
        function showSecondImage() {
            var button = document.getElementById('button');
            var profileImage = document.getElementById('profile');
    
            button.style.display = 'none';
            profileImage.src = 'assets/img/profile.jpg';
        }
    </script>
<!--     <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-W5VFYVPNDZ"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'G-W5VFYVPNDZ');
    </script> -->


</head>

<body>
    <div class="container">
        <div class="row" style="margin-top: 3em;">
            <div class="col-sm-12" style="margin-bottom: 1em;">
            <h3 class="display-4" style="text-align: center;"><span style="font-weight: bold;">Xiaoyan</span> Zhang</h3>
            </div>
            <br>
            <div class="col-md-8" style="">
                
                <p>I am a senior student in the Artificial Intelligence College at Anhui University, expecting to graduate in 2025. I currently serve as a research assistant 
                  at the <a href="https://cs.ahu.edu.cn/2024/0423/c10991a334664/page.htm" target="_blank">Anhui Provincial International Joint Research Center for Advanced Technology in Medical Imaging</a>, 
                  under the guidance of <a href="https://www.linkedin.com/in/jin-zhe-1151b892/?originalSubdomain=cn" target="_blank">Prof. Zhe Jin</a> 
                  and <a href="https://xingbod.github.io/" target="_blank">Dr. Xingbo Dong</a>. 
                  
                    In the summer of 2023, I had the opportunity to visit Nanyang Technological University, Singapore, where I completed a summer course on "Machine Learning & Deep Learning Methodologies".
                    
                    I am also honored to be working as a research assistant at the Video and Image Processing Laboratory (VIPER) at Purdue University, starting in 2024, 
                    under the supervision of <a href="https://engineering.purdue.edu/~zhu0/" target="_blank">Prof. Fengqing Maggie Zhu</a>.
                </p>
                <p>
                My research interests include computer vision and its applications to medical imaging, continual learning, pattern recognition, and compression. I am always open to exploring new research areas and welcome potential collaborations.
                    
                    Currently, I am applying for Ph.D. positions for Fall 2025. Please feel free to contact me for any inquiries or collaboration opportunities.
                </p>
                <p>
                  Email: <a href="mailto:wa2114214@stu.ahu.edu.cn">wa2114214 AT stu D0t ahu DOt edu Dot cn</a>
                </p>

                <p>
                  <a href="assets/pdf/CV.pdf" target="_blank" style="margin-right: 15px"><i class="fa fa-address-card fa-lg"></i> CV</a>
                  <a href="https://scholar.google.com.hk/citations?user=eKzyd0YAAAAJ&hl=zh-CN" target="_blank" style="margin-right: 15px"><i class="fa-solid fa-book"></i> Google Scholar</a>
                </p>
              
<!--                 <p>
                    <a href="https://scholar.google.com/citations?user=HmQECwsAAAAJ&hl=en&oi=ao" target="_blank" style="margin-right: 15px"><i class="fa-solid fa-book"></i> Google Scholar</a>
                    <a href="https://www.linkedin.com/in/zhaoying-pan-296942153/" target="_blank" style="margin-right: 15px"><i class="fab fa-linkedin fa-lg"></i> LinkedIn</a>
                    <a href="https://twitter.com/ZhaoyingPan" target="_blank" style="margin-right: 15px"><i class="fab fa-twitter fa-lg"></i> Twitter</a>
                </p> -->
    
            </div>
<!--             <div class="col-md-4" style="">
                <img id="profile" src="assets/img/goose.jpg" class="img-thumbnail" width="280px" alt="Profile picture" />
                <button id="button" onclick="showSecondImage();" style="border: none; margin-top: 5px;">Show My Photo!</button>
            </div> -->
          <div class="col-md-4">
            <img id="profile" src="assets/img/xiaoyan_zhang_picture_2.jpg" class="img-thumbnail" width="230px" alt="Xiaoyan Zhang Picture" />
          </div>

        </div>


        <div class="row" style="margin-top: 3em;">
            <div class="col-sm-10" style="">
                <h4>Education</h4>

                <div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-2"><img src="assets/img/purdue.png" alt="PU" width="120" height="100"></div><div class="col-sm-10">
                    <b>Purdue University</b> <span style="float: right;">2024-present</span>
                    <br><span style="font-style: italic;">Intern</span> in Electrical and Computer Engineering
                    <br>Advisor: <a href="https://engineering.purdue.edu/~zhu0/" target="_blank">Prof. Fengqing Maggie Zhu</a> 
<!--                   and <a href="https://engineering.purdue.edu/~ace/" target="_blank">Prof. Edward J. Delp</a> -->
                </div> </div> </div>

                <div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-2"><img src="assets/img/ntu.png" alt="NTU" width="140" height="70"></div><div class="col-sm-10">
                    <b>Nanyang Technological University</b><span style="float: right;">July 2023-August 2023</span>
                    <br>2023 Summer School Program
                    <br>Theme: Machine Learning & Deep Learning Methodologies
                    <br>Advisor: <a href="https://www.ntu.edu.sg/ncpa/faculty-directory/the-faculty/chew-soon-beng#Content_C009_Col00" target="_blank">Prof. Chew Soon Beng </a>
                </div> </div> </div>
                
                <div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-2"><img src="assets/img/ahu.png" alt="AHU" width="120" height="120"></div><div class="col-sm-10">
                    <b>Anhui University</b> <span style="float: right;">2021-2025</span>
                    <br><span style="font-style: italic;">Bachelor of Engineering</span> in Artificial Intelligence
                    <br>GPA: 4.33/5.00, Rank: 1/251
<!--                     <br>Thesis: <span style="font-style: italic;">Image Caption Generating of High-Resolution Remote Sensing Images.</span> (Bachelor’s Thesis with Honors) -->
                    <br>Advisor: <a href="https://www.linkedin.com/in/jin-zhe-1151b892/?originalSubdomain=cn" target="_blank">Prof. Zhe Jin</a> and <a href="https://xingbod.github.io/" target="_blank">Dr. Xingbo Dong</a> 
                </div> </div> </div>
            </div>
        </div>

        <div class="row" style="margin-top: 3em;">
            <div class="col-sm-12" style="">
                <h4>Publications</h4>






<div style="margin-bottom: 3em;"> 
    <div class="row">
        <div class="col-sm-3">
            <img src="assets/img/projects/PRCV2024_Learning_Frequency1.png" class="img-fluid img-thumbnail" alt="Project image">
        </div>
        <div class="col-sm-9">
            <a style="font-weight: bold";>Learning Frequency and Structure in UDA for Medical Object Detection</a>
            <br><span style="font-weight: bold";>Zhang Xiaoyan</span>*, Liwen Wang*, Guannan He, Ying Tan, Shengli Li, Bin Pu, Zhe Jin, Wen Sha, Xingbo Dong.
            <br><span style="font-style: italic;">Chinese Conference on Pattern Recognition and Computer Vision (PRCV)</span>, 2024
            <br><a href="assets/pdf/PRCV2024_839_Learning_Frequency_and_Structure_in_UDA_for_Medical_Object_Detection.pdf" target="_blank">Paper</a>
          / <button class="btn btn-link" type="button" data-toggle="collapse" data-target="#10.1007/978-981-97-8496-7_36" aria-expanded="false" aria-controls="10.1007/978-981-97-8496-7_36" style="margin-left: -6px; margin-top: -2px;">Expand bibtex</button>

          <div class="collapse" id="10.1007/978-981-97-8496-7_36">
                <div class="card card-body">
                    <pre><code>@InProceedings{10.1007/978-981-97-8496-7_36, author="Wang, Liwen and Zhang, Xiaoyan and He, Guannan and Tan, Ying and Li, Shengli and Pu, Bin and Jin, Zhe and Sha, Wen and Dong, Xingbo",
                    editor="Lin, Zhouchen and Cheng, Ming-Ming and He, Ran and Ubul, Kurban and Silamu, Wushouer and Zha, Hongbin and Zhou, Jie and Liu, Cheng-Lin",
                    title="Learning Frequency and Structure in UDA for Medical Object Detection",
                    booktitle="Pattern Recognition and Computer Vision",
                    year="2025",
                    publisher="Springer Nature Singapore",
                    address="Singapore",
                    pages="518--532",
                    abstract="In medical imaging applications, particularly in cardiac and skeletal analysis, the anatomical structure detection is crucial for diagnosing cardiac disease and other disease. However, the domain gap between images acquired from different sources or modalities poses a significant challenge and impedes model generalization across diverse patient populations and imaging conditions. Bridging this gap is particularly essential in image-based diagnosis, where subtle variations in anatomical structures and imaging characteristics can profoundly impact diagnostic performance. Take fetal cardiac ultrasound images as an example, this paper proposes a novel method for unsupervised domain adaptive fetal cardiac structure detection. The method integrates both the frequency-based distributional properties and anatomical structural information inherent in medical images. Specifically, we introduce a Frequency Distribution Alignment (FDA) module and an Organ Structure Alignment (OSA) module to mitigate detection misalignment across different hospital settings. We demonstrates the effectiveness of these modules through extensive experiments. Our method significantly improves the performance of fetal cardiac structure detection tasks, enabling adaptation to diverse hospital scenarios and showcasing its potential in addressing domain gaps in medical imaging.",
                    isbn="978-981-97-8496-7"
                    }</code></pre>
                </div>
            </div>
          
            <br> We proposed a novel method for unsupervised domain adaptive fetal cardiac structure detection to address the domain gap between different sources or modalities in medical imaging.
        </div>
    </div>
</div>



              
                       
<div style="margin-bottom: 3em;">
    <div class="row">
        <div class="col-sm-3">
            <img src="assets/img/projects/CVPR2024_Privacy_Perserving.png" class="img-fluid img-thumbnail" alt="Project image">
        </div>
        <div class="col-sm-9">
            <a style="font-weight: bold;">Validating Privacy-Preserving Face Recognition under a Minimum Assumption</a>
            <br>Zhang Hui, Dong Xingbo, Lai YenLung, Zhou Ying, <span style="font-weight: bold;">Zhang Xiaoyan</span>, Lv Xingguo, Jin Zhe, Li Xuejun.
            <br><span style="font-style: italic;">IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</span>, 2024
            <br><a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Zhang_Validating_Privacy-Preserving_Face_Recognition_under_a_Minimum_Assumption_CVPR_2024_paper.pdf" target="_blank">Paper</a> / 
            <a href="https://github.com/Beauty9882/MAP2V" target="_blank">Code</a> / <button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapsezhang2024validating" aria-expanded="false" aria-controls="collapsezhang2024validating" style="margin-left: -6px; margin-top: -2px;">Expand bibtex</button>
            
            <div class="collapse" id="collapsezhang2024validating">
                <div class="card card-body">
                    <pre><code>@inproceedings{zhang2024validating,
                    title={Validating Privacy-Preserving Face Recognition under a Minimum Assumption},
                    author={Zhang, Hui and Dong, Xingbo and Lai, YenLung and Zhou, Ying and Zhang, Xiaoyan and Lv, Xingguo and Jin, Zhe and Li, Xuejun},
                    booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
                    pages={12205--12214},
                    year={2024},
                    publisher={CVPR}
                  }</code></pre>
                </div>
            </div>
            <br> We proposed the Map2V, a novel privacy validation method using deep image priors and zeroth-order gradient estimation for privacy-preserving face recognition (PPFR) schemes. 
            Map2V not only exposes the vulnerabilities of SOTA PPFRs but can also be employed to validate the privacy protection capacity of naive FR and PPFR systems.
        </div>
    </div>
</div>


              
            </div>
        </div>


<div style="margin-bottom: 3em;"> 
  <div class="row">
    <div class="col-sm-3">
      <img src="assets/img/projects/MadiMa_metafood_image_dist.png" class="img-fluid img-thumbnail" alt="Project image">
    </div>
        <div class="col-sm-9">
          <a style="font-weight: bold";>MFP3D: Monocular Food Portion Estimation Leveraging 3D Point Clouds (Oral)</a>
          <br>Jinge Ma, <span style="font-weight: bold";>Xiaoyan Zhang</span>, Gautham Vinod, Siddeshwar Raghavan, Jiangpeng He, Fengqing Zhu.
          <br><span style="font-style: italic;">International Conference on Pattern Recognition (ICPR) MADiMa workshop</span>, 2024
          <br><a href="assets/pdf/MFP3D_MadiMa2024.pdf" target="_blank">Paper</a>
<!--            / <a href="https://github.com/xiaoyuan1996/SemanticLocalizationMetrics" target="_blank">Code</a>  -->
          / <button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapsema2024mfp3d" aria-expanded="false" aria-controls="collapsema2024mfp3d" style="margin-left: -6px; margin-top: -2px;">Expand bibtex</button>
            
            <div class="collapse" id="collapsema2024mfp3d">
                <div class="card card-body">
                    <pre><code>@article{ma2024mfp3d,
                      title={MFP3D: Monocular Food Portion Estimation Leveraging 3D Point Clouds},
                      author={Ma, Jinge and Zhang, Xiaoyan and Vinod, Gautham and Raghavan, Siddeshwar and He, Jiangpeng and Zhu, Fengqing},
                      journal={arXiv preprint arXiv:2411.10492},
                      year={2024}
                  }</code></pre>
                </div>
            </div>    
        <br> We propose MFP3D, a new framework for accurate food portion estimation from a single image. It uses 3D reconstruction, feature extraction, 
          and deep learning to estimate food volume and energy content, showing improved accuracy on the MetaFood3D dataset compared to existing approaches.
      </div> 
  </div> 
</div>


<div style="margin-bottom: 3em;"> 
  <div class="row">
    <div class="col-sm-3">
      <img src="assets/img/projects/PR2024_Paimprint.png" class="img-fluid img-thumbnail" alt="Project image">
    </div>
        <div class="col-sm-9">
          <a style="font-weight: bold";>Single Source Domain Generalization for Palm Biometrics</a>
          <br>Congcong Jia, Xingbo Dong, Yen Lung Lai, Andrew Beng Jin Teoh, Ziyuan Yang, <span style="font-weight: bold";>Xiaoyan Zhang</span>, Liwen Wang, Zhe Jin, Lianqiang Yang.
          <br><span style="font-style: italic;">Pattern Recognition</span>
          <br><a href="https://pdf.sciencedirectassets.com/272206/AIP/1-s2.0-S0031320325002808/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjECAaCXVzLWVhc3QtMSJHMEUCIQCLBFrfRfNTIWVuiv6nMv258wohbKZFk2HxhZIT8VagiwIgSECxFHi5ziDa1vG6ip6TypWZKMVZ%2FaWb%2BlHtEX7y%2BUAquwUIif%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARAFGgwwNTkwMDM1NDY4NjUiDHqCZqXcXKXb04h7OSqPBdDSklcFS2egdHd0QskJj7lLDy9%2F9O%2BXe0R1wo0IrQ6mXJZWQNGKAw9hGzHjhXc2tWZmUC%2FyyCRx4SMiEOhbHbtYOck5gJp8S8%2FjOG4eW0bj64B1dN7FrSSgnVBo1AVIcP3X8v08GfKMwpoqUvwed0nfnN%2Fa%2Bc1sSHBNRCY6Ck9goq2kZ857f7xuGxzK3JKoMJSqA1oRo4q2G1I4lWM2xcRFJGh5OdkXdGJTjsdcOlE7JVS%2B%2F8mufAnUXa77y0y9%2Fn08AfrZlKseBuC5vXpluP3mW%2BtX5K1v4cazN%2F4f5PZeEXRYGqeFr6IKMOAIkaaKwfHHM%2Bl5zoN1LCYNppngYCts9THDEhuOmp0vnrzvar7dEKZXTVbNnElndQX9cj%2Bgvw1voeOBaDSwHpeJgCs8ts010rmQCIC7BTjVsrfr1xielP2Ysl1suBWYnXTo15EEyAYG6BLV7j%2BB%2BI342w3%2BDJmAFgdBlrHHO2O3KDsCKd8tcoIP7x6UhzbtPsFEGRjuLyExbBK5EWhecvb4ESVQ78WfCscLyvUiqzw8TJ7ksNH6V6OXNNTJqmR4Ln%2B8k0jspOflx%2FomtF2506u9toFIrR0YO6OjVNOMYnaae10w3H67Qa5TnmLt%2FK4D0O8hkE0lwjmP0XoSns3hZ5g428mxfH88wvEz%2FA7G2H8vxF8COTXKanln%2FvC5XuBpaDrxjmh%2B6l8BHQ6NYNC%2B12yXJix83261u7LfKzeXVqWl8sCCpWn7wUxNnl%2FiYWd5gYodNdqQ7d6AjcG5%2BU4c5g0l0kA3P7y3hYVtD9Mhyy7MWc0zZmn8YYkWnniUBfvnsNQQDJneS17g0Z32qDftoxId3L66vSnCsaHewnt6C8TzVztQ16Ywo%2ByjvwY6sQEQ6viT%2FUkRbMBGYCkUr3Gg656vezPESqw5USMzlVNooWWqRmD74IrloPILdDBi8bjT90NB56AwnO9%2BvwYthhHKID%2BgvI42TCKz0PAoiqICkHn5DUgGyi7mWXQ1bJT1jvpB5qFR5afxu%2Fj2RsgmJizsWExkzSeIUhQqwHNxyoQCbwOQWWs5zPY7PbrHSBwUdhkfgYPy20zmjeNSEMX9%2Bt8Zx076JYTB6vK1jP6%2BnPhxxFI%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20250330T083133Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAQ3PHCVTY7RD56KIU%2F20250330%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=f9ca6e2e712d4f12415a10789c89f9930f731e21dc45a07dc3e8db0ccc75b0b0&hash=1acffbfd8706c3300a27b1929e377026d3655bba2677d97c0f2429e648de4101&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S0031320325002808&tid=spdf-97128174-c1de-4f23-b7ac-de61181f67d9&sid=b4141fe96dedd34437787bd250a5fdbf529fgxrqa&type=client&tsoh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&rh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&ua=0f125b555f5255535607&rr=9286405c79327aa9&cc=us" target="_blank">Paper</a>
           / <a href="https://github.com/xiaoyuan1996/SemanticLocalizationMetrics" target="_blank">Code</a> 
        <br> We proposed to improve palmprint recognition by addressing the challenge of single-source domain generalization through data alignment techniques: Fourier Alignment Transform and Histogram Matching.
      </div> 
  </div> 
</div>

      

<div style="margin-bottom: 3em;"> 
  <div class="row">
    <div class="col-sm-3">
      <img src="assets/img/projects/TIP_Duality_motivation.png" class="img-fluid img-thumbnail" alt="Project image">
    </div>
        <div class="col-sm-9">
          <a style="font-weight: bold";>Low-Light Image Enhancement with Luminance Duality (Under review)</a>
          <br>Xingguo Lv, Xingbo Dong, <span style="font-weight: bold";>Xiaoyan Zhang</span>, Jiewen Yang, Zhe Jin, Xuejun Li, Jean-Luc Dugelay.
          <br><span style="font-style: italic;">IEEE Transactions on Circuits and Systems for Video Technology (TCSVT)</span>
<!--           <br><a href="assets/img/projects/TIP_Duality_motivation.pdf" target="_blank">Paper</a> -->
<!--            / <a href="https://github.com/xiaoyuan1996/SemanticLocalizationMetrics" target="_blank">Code</a>  -->
        <br> We introduce a novel low-light image enhancement framework that integrates global and local luminance differences 
          through its Lumimator and NLRestorer modules, achieving superior image quality compared to existing methods.
      </div> 
  </div> 
</div>

<div style="margin-bottom: 3em;"> 
  <div class="row">
    <div class="col-sm-3">
      <img src="assets/img/projects/TMM_dataset.png" class="img-fluid img-thumbnail" alt="Project image">
    </div>
        <div class="col-sm-9">
          <a style="font-weight: bold";>Long-Tailed Continual Learning For Visual Food Recognition (Under review)</a>
          <br>Jiangpeng He, <span style="font-weight: bold";>Xiaoyan Zhang</span>, Luotao Lin, Jack Ma, Heather A. Eicher-Miller, Fengqing Zhu.
          <br><span style="font-style: italic;">IEEE Transactions on Multimedia (TMM)</span>
          <br><a href="assets/pdf/TMM_2023_JH_Long_tailed_continual_learning__new_.pdf" target="_blank">Paper</a>
<!--            / <a href="https://github.com/xiaoyuan1996/SemanticLocalizationMetrics" target="_blank">Code</a>  -->
        <br> We provide the VFN186 dataset, along with a novel framework that enhances generalization on long-tailed food distribution 
          using knowledge distillation and a CAM-CutMix-based augmentation technique.
      </div> 
  </div> 
</div>


<div style="margin-bottom: 3em;"> 
  <div class="row">
    <div class="col-sm-3">
      <img src="assets/img/projects/CVPR2025_Investigating.png" class="img-fluid img-thumbnail" alt="Project image">
    </div>
        <div class="col-sm-9">
          <a style="font-weight: bold";>Exploring Model Weight Uncertainty for Domain Adaptive Medical Image Segmentation (Under review)</a>
          <br>Liwen Wang, Xingguo Lv, <span style="font-weight: bold";>Xiaoyan Zhang</span>, Zhe Jin, Xingbo Dong.
          <br><span style="font-style: italic;"> IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</span>, 2025
<!--           <br><a href="assets/pdf/PAAA_CVPR2024_MetaFood_Challenge_Report.pdf" target="_blank">Paper</a> -->
<!--            / <a href="https://github.com/xiaoyuan1996/SemanticLocalizationMetrics" target="_blank">Code</a>  -->
        <br> We developed a unified approach for both test-time adaptation (TTA) and continual test-time adaptation (CTTA) that addresses distribution shifts
          in medical images. Our method introduces visual prompt training with a frozen pre-trained model and utilizes a novel uncertainty-based entropy metric 
          along with an Adaptive Score to optimize model adaptation effectively.
      </div> 
  </div> 
</div>
      


<div style="margin-bottom: 3em;"> 
  <div class="row">
    <div class="col-sm-3">
      <img src="assets/img/projects/PAAA2024_MetaFood_challenge_dataset.png" class="img-fluid img-thumbnail" alt="Project image">
    </div>
        <div class="col-sm-9">
          <a style="font-weight: bold";>Physically Informed 3D Food Reconstruction: Methods and Results (Under review)</a>
          <br>Jiangpeng He, Yuhao Chen, Gautham Vinod, <span style="font-weight: bold";>Xiaoyan Zhang</span>, Talha Ibn Mahmud, Umair Haroon, Ricardo Marques, Petia Radeva, Jiadong Tang, Dianyi Yang,
          Yu Gao, Zhaoxiang Liang, Yawei Jueluo, Chengyu Shi, Pengyu Wang, Pengcheng Xi, Alexander Wong, Edward Delp, Fengqing Zhu.
          <br><span style="font-style: italic;"> Pattern Analysis and Applications (PAA)</span>
          <br><a href="assets/pdf/PAA-CVPR2024-MetaFood-Challenge-Report.pdf" target="_blank">Paper</a>
<!--            / <a href="https://github.com/xiaoyuan1996/SemanticLocalizationMetrics" target="_blank">Code</a>  -->
        <br> This paper presents the MetaFood Workshop challenge on Physically Informed 3D Food Reconstruction, discusses the outcomes, 
          and provides insights into future directions for 3D food reconstruction in nutrition monitoring applications.
      </div> 
  </div> 
</div>






      

 <div class="row" style="margin-top: 3em; margin-bottom: 1em;">
            <div class="col-sm-12" style="">
                <h4>Teaching Experience</h4>
                <ul>
                    <li><b>24 Fall: ZJ52014 Introduction to Artificial Intelligence</b>, <span style="font-style: italic;">Undergraduate Teaching Assistant</span> <span style="float: right;">Anhui University</span></li>
                    <li><b>24 Fall: ZX52340 Java Technology and Its Application (Practice)</b>, <span style="font-style: italic;">Undergraduate Teaching Assistant</span> <span style="float: right;">Anhui University</span></li>
                    <li><b>May 23 -- May 24: Guoyuan Dream Plan</b>, <span style="font-style: italic;">Academic Peer Mentor</span> <span style="float: right;">Anhui University</span></li>
                </ul>
            </div>
        </div>
      

<div class="row" style="margin-top: 3em; margin-bottom: 1em;">          
  <div class="col-sm-12" style="">
      <h4>Awards</h4>
      <ul>
        <li><b>Outstanding Graduate of Anhui Province</b>, <span style="font-style: italic;">Ministry of Education of Anhui Province</span> <span style="float: right;">2025</span></li>
        <li><b>National Scholarship</b>, <span style="font-style: italic;">Ministry of Education of the People's Republic of China</span> <span style="float: right;">2024</span></li>
        <li><b>Pacemaker to Merit Student</b>, <span style="font-style: italic;">Anhui University</span> <span style="float: right;">2022, 2023, 2024</span></li>
        <li><b>Merit Student</b>, <span style="font-style: italic;">Anhui University</span> <span style="float: right;">2022, 2023, 2024</span></li>
        <!--         <li><b>Honarable Mentioned</b> in the Interdisciplinary Contest in Modeling, <span style="font-style: italic;">The Consortium for Mathematics and Its Application</span> <span style="float: right;">2024</span></li>
        <li><b>Outstanding Mentioned</b> in the Second "Huashu Cup" International Mathematical Contest in Modeling, <span style="font-style: italic;">Big Data and Mathematical Modeling Committee of China Society for Future Studies</span> <span style="float: right;">2024</span></li> -->
        <li><b>Song Qingling Future Grant for Discipline Focus Students</b> (0.05%), <span style="font-style: italic;">The China Song Qingling Foundation</span> <span style="float: right;">2024</span></li>
        
<!--         <li><b>Provincial Second Prize</b> in China Undergraduate Mathematical Contest in Modeling, <span style="font-style: italic;">China Society for Industrial and Applied Mathematics</span> <span style="float: right;">2024</span></li> -->
        <li><b>Excellent Student Scholarship</b>, <span style="font-style: italic;">Anhui University</span> <span style="float: right;">2023</span></li>
        <li><b>Academic Science and Technology Scholarship</b>, <span style="font-style: italic;">Anhui University</span> <span style="float: right;">2023</span></li>
<!--         <li><b>Pacemaker to Merit Student</b>, <span style="font-style: italic;">Anhui University</span> <span style="float: right;">2023</span></li> -->
<!--         <li><b>Merit Student</b>, <span style="font-style: italic;">Anhui University</span> <span style="float: right;">2023</span></li> -->
<!--         <li><b>Provincial Silver Award</b> in China International College Students’ Innovation Competition, <span style="font-style: italic;">Ministry of Education of Anhui Province</span> <span style="float: right;">2023</span></li> -->
<!--         <li><b>Pacemaker to Merit Student</b>, <span style="font-style: italic;">Anhui University</span> <span style="float: right;">2022</span></li> -->
<!--         <li><b>Merit Student</b>, <span style="font-style: italic;">Anhui University</span> <span style="float: right;">2022</span></li> -->
        <li><b>National Encouragement Scholarship</b>, <span style="font-style: italic;">Ministry of Education of Anhui Province</span> <span style="float: right;">2022</span></li>
        
        

        
      </ul>
  </div>

  
</div>
      

      

<!--         <div class="row" style="margin-top: 3em; margin-bottom: 1em;">
            <div class="col-sm-12" style="">
                <h4>Projects</h4>
                <ul>
                    <li><b>The Evolution of AI and Data Mining</b>: We analyzed computer science papers over half a century and revealed the evolution of domains by examining how the distribution changes over time. Check the <a href="https://www.youtube.com/watch?v=J0nB0uRRCo4" target="_blank">video</a>.</li>
                </ul>
            </div>
        </div>
 -->

       

        <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=cdc0b0&w=300&t=tt&d=XsaXIdSbwmNV33O0rzrWJ8b6Pj3KX4m36bLU7Nm9TKM&co=ffffff&cmn=6ca6cd&cmo=828282&ct=363636'></script>
    
    </div>

    <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js"
      integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN"
      crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js"
      integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q"
      crossorigin="anonymous"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js"
      integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl"
      crossorigin="anonymous"></script>
    <footer style="padding-left: 220px;">
        <p>Visitor Count since 22/09/2024. Thanks for the website template from <a href="https://m-niemeyer.github.io/" target="_blank">Michael Niemeyer</a>. Last updated on 03/30/2025<br>
        </p>
    </footer>
</body>

</html>
    
