<!doctype html>
<html lang="en">

<head>
  <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css"
        integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/all.min.css" integrity="sha512-xh6O/CkQoPOWDdYTDqeRdPCVd1SpvCA9XXcUnZS2FmJNp1coAFzvtCN9BmamE+4aHK8yyUHUSCcJHgXloTyT2A==" crossorigin="anonymous" referrerpolicy="no-referrer" />

    <title>Xiaoyan Zhang</title>
    <link rel="icon" type="image/x-icon" href="assets/goose.ico">
  
    <script>
        function showSecondImage() {
            var button = document.getElementById('button');
            var profileImage = document.getElementById('profile');
    
            button.style.display = 'none';
            profileImage.src = 'assets/img/profile.jpg';
        }
    </script>
<!--     <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-W5VFYVPNDZ"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'G-W5VFYVPNDZ');
    </script> -->


</head>

<body>
    <div class="container">
        <div class="row" style="margin-top: 3em;">
            <div class="col-sm-12" style="margin-bottom: 1em;">
            <h3 class="display-4" style="text-align: center;"><span style="font-weight: bold;">Xiaoyan</span> Zhang</h3>
            </div>
            <br>
            <div class="col-md-8" style="">
                
                <p>I am a recent graduate from Anhui University. 
                  In 2023, I participated in a summer program at Nanyang Technological University, Singapore, which broadened my international academic experience. 
                  Since Fall 2024, I have been collaborating with the Video and Image Processing Laboratory (VIPER) under the supervision of <a href="https://engineering.purdue.edu/~zhu0/" target="_blank">Prof. Fengqing Maggie Zhu</a>, where I work on image understanding and intelligent food analysis.
                  In Spring 2026, I will continue my studies at the University of Michigan, focusing on visual understanding and data-driven modeling.
                </p>
                <p>
                  My research interests include visual recognition, food understanding, and health-related domains.     
                </p>
               
                <p>
                  Email: <a href="mailto:wa2114214@stu.ahu.edu.cn">wa2114214 AT stu.ahu.edu.cn</a>
                </p>

                <p>
                  <!-- <a href="assets/pdf/CV.pdf" target="_blank" style="margin-right: 15px"><i class="fa fa-address-card fa-lg"></i> CV</a> -->
                  <a href="https://scholar.google.com.hk/citations?user=eKzyd0YAAAAJ&hl=zh-CN" target="_blank" style="margin-right: 15px"><i class="fa-solid fa-book"></i> Google Scholar</a>
                </p>
              
<!--                 <p>
                    <a href="https://scholar.google.com/citations?user=HmQECwsAAAAJ&hl=en&oi=ao" target="_blank" style="margin-right: 15px"><i class="fa-solid fa-book"></i> Google Scholar</a>
                    <a href="https://www.linkedin.com/in/zhaoying-pan-296942153/" target="_blank" style="margin-right: 15px"><i class="fab fa-linkedin fa-lg"></i> LinkedIn</a>
                    <a href="https:" target="_blank" style="margin-right: 15px"><i class="fab fa-twitter fa-lg"></i> Twitter</a>
                </p> -->
    
            </div>
<!--             <div class="col-md-4" style="">
                <img id="profile" src="assets/img/goose.jpg" class="img-thumbnail" width="280px" alt="Profile picture" />
                <button id="button" onclick="showSecondImage();" style="border: none; margin-top: 5px;">Show My Photo!</button>
            </div> -->
          <div class="col-md-4">
            <img id="profile" src="assets/img/xiaoyan_zhang_picture_2.jpg" class="img-thumbnail" width="230px" alt="Xiaoyan Zhang Picture" />
          </div>

        </div>


        <div class="row" style="margin-top: 3em;">
            <div class="col-sm-10" style="">
                <h4>Education</h4>


                <!-- <div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-2"><img src="assets/img/ntu.png" alt="NTU" width="140" height="70"></div><div class="col-sm-10">
                    <b>Nanyang Technological University</b><span style="float: right;">July 2023-August 2023</span>
                    <br>2023 Summer School Program
                    <br>The
                </div> </div> </div> -->
                
                <div style="margin-bottom: 3em;"> <div class="row"><div class="col-sm-2"><img src="assets/img/ahu.png" alt="AHU" width="120" height="120"></div><div class="col-sm-10">
                    <b>Anhui University</b> <span style="float: right;">2021-2025</span>
                    <br><span style="font-style: italic;">Bachelor of Engineering</span> in Artificial Intelligence
                    <br>GPA: 4.34/5.00, Rank: 1/251 
                </div> </div> </div>
            </div>
        </div>

        <div class="row" style="margin-top: 3em;">
            <div class="col-sm-12" style="">
                <h4>Publications</h4>






<div style="margin-bottom: 3em;"> 
    <div class="row">
        <div class="col-sm-3">
            <img src="assets/img/projects/PRCV2024_Learning_Frequency1.png" class="img-fluid img-thumbnail" alt="Project image">
        </div>
        <div class="col-sm-9">
            <a style="font-weight: bold";>Learning Frequency and Structure in UDA for Medical Object Detection</a>
            <br><span style="font-weight: bold";>Zhang Xiaoyan</span>*, Liwen Wang*, Guannan He, Ying Tan, Shengli Li, Bin Pu, Zhe Jin, Wen Sha, Xingbo Dong.
            <br><span style="font-style: italic;">Chinese Conference on Pattern Recognition and Computer Vision (PRCV)</span>, 2024
            <br><a href="https://link.springer.com/chapter/10.1007/978-981-97-8496-7_36" target="_blank">Paper</a>
          / <button class="btn btn-link" type="button" data-toggle="collapse" data-target="#10.1007/978-981-97-8496-7_36" aria-expanded="false" aria-controls="10.1007/978-981-97-8496-7_36" style="margin-left: -6px; margin-top: -2px;">Expand bibtex</button>

          <div class="collapse" id="10.1007/978-981-97-8496-7_36">
                <div class="card card-body">
                    <pre><code>@InProceedings{10.1007/978-981-97-8496-7_36, author="Wang, Liwen and Zhang, Xiaoyan and He, Guannan and Tan, Ying and Li, Shengli and Pu, Bin and Jin, Zhe and Sha, Wen and Dong, Xingbo",
                    editor="Lin, Zhouchen and Cheng, Ming-Ming and He, Ran and Ubul, Kurban and Silamu, Wushouer and Zha, Hongbin and Zhou, Jie and Liu, Cheng-Lin",
                    title="Learning Frequency and Structure in UDA for Medical Object Detection",
                    booktitle="Pattern Recognition and Computer Vision",
                    year="2025",
                    publisher="Springer Nature Singapore",
                    address="Singapore",
                    pages="518--532",
                    abstract="In medical imaging applications, particularly in cardiac and skeletal analysis, the anatomical structure detection is crucial for diagnosing cardiac disease and other disease. However, the domain gap between images acquired from different sources or modalities poses a significant challenge and impedes model generalization across diverse patient populations and imaging conditions. Bridging this gap is particularly essential in image-based diagnosis, where subtle variations in anatomical structures and imaging characteristics can profoundly impact diagnostic performance. Take fetal cardiac ultrasound images as an example, this paper proposes a novel method for unsupervised domain adaptive fetal cardiac structure detection. The method integrates both the frequency-based distributional properties and anatomical structural information inherent in medical images. Specifically, we introduce a Frequency Distribution Alignment (FDA) module and an Organ Structure Alignment (OSA) module to mitigate detection misalignment across different hospital settings. We demonstrates the effectiveness of these modules through extensive experiments. Our method significantly improves the performance of fetal cardiac structure detection tasks, enabling adaptation to diverse hospital scenarios and showcasing its potential in addressing domain gaps in medical imaging.",
                    isbn="978-981-97-8496-7"
                    }</code></pre>
                </div>
            </div>
          
            <br> We proposed a novel method for unsupervised domain adaptive fetal cardiac structure detection to address the domain gap between different sources or modalities in medical imaging.
        </div>
    </div>
</div>



              
                       
<div style="margin-bottom: 3em;">
    <div class="row">
        <div class="col-sm-3">
            <img src="assets/img/projects/CVPR2024_Privacy_Perserving.png" class="img-fluid img-thumbnail" alt="Project image">
        </div>
        <div class="col-sm-9">
            <a style="font-weight: bold;">Validating Privacy-Preserving Face Recognition under a Minimum Assumption</a>
            <br>Zhang Hui, Dong Xingbo, Lai YenLung, Zhou Ying, <span style="font-weight: bold;">Zhang Xiaoyan</span>, Lv Xingguo, Jin Zhe, Li Xuejun.
            <br><span style="font-style: italic;">IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</span>, 2024
            <br><a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Zhang_Validating_Privacy-Preserving_Face_Recognition_under_a_Minimum_Assumption_CVPR_2024_paper.pdf" target="_blank">Paper</a> / 
            <a href="https://github.com/Beauty9882/MAP2V" target="_blank">Code</a> / <button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapsezhang2024validating" aria-expanded="false" aria-controls="collapsezhang2024validating" style="margin-left: -6px; margin-top: -2px;">Expand bibtex</button>
            
            <div class="collapse" id="collapsezhang2024validating">
                <div class="card card-body">
                    <pre><code>@inproceedings{zhang2024validating,
                    title={Validating Privacy-Preserving Face Recognition under a Minimum Assumption},
                    author={Zhang, Hui and Dong, Xingbo and Lai, YenLung and Zhou, Ying and Zhang, Xiaoyan and Lv, Xingguo and Jin, Zhe and Li, Xuejun},
                    booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
                    pages={12205--12214},
                    year={2024},
                    publisher={CVPR}
                  }</code></pre>
                </div>
            </div>
            <br> We proposed the Map2V, a novel privacy validation method using deep image priors and zeroth-order gradient estimation for privacy-preserving face recognition (PPFR) schemes. 
            Map2V not only exposes the vulnerabilities of SOTA PPFRs but can also be employed to validate the privacy protection capacity of naive FR and PPFR systems.
        </div>
    </div>
</div>
   
            </div>
        </div>


<div style="margin-bottom: 3em;"> 
  <div class="row">
    <div class="col-sm-3">
      <img src="assets/img/projects/TMM_dataset.png" class="img-fluid img-thumbnail" alt="Project image">
    </div>
        <div class="col-sm-9">
          <a style="font-weight: bold";>Long-Tailed Continual Learning For Visual Food Recognition</a>
          <br>Jiangpeng He, <span style="font-weight: bold";>Xiaoyan Zhang</span>, Luotao Lin, Jack Ma, Heather A. Eicher-Miller, Fengqing Zhu.
          <br><span style="font-style: italic;">IEEE Transactions on Multimedia (TMM)</span>
          <br><a href="https://arxiv.org/pdf/2307.00183" target="_blank">Paper</a>
<!--            / <a href="https://github.com/xiaoyuan1996/SemanticLocalizationMetrics" target="_blank">Code</a>  -->
          / <button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapsehe2025longtailedcontinuallearningvisual" aria-expanded="false" aria-controls="collapsehe2025longtailedcontinuallearningvisual" style="margin-left: -6px; margin-top: -2px;">Expand bibtex</button>
            <div class="collapse" id="collapsehe2025longtailedcontinuallearningvisual">
                <div class="card card-body">
                    <pre><code>@misc{he2025longtailedcontinuallearningvisual,
                        title={Long-Tailed Continual Learning For Visual Food Recognition}, 
                        author={Jiangpeng He and Xiaoyan Zhang and Luotao Lin and Jack Ma and Heather A. Eicher-Miller and Fengqing Zhu},
                        year={2025},
                        eprint={2307.00183},
                        archivePrefix={arXiv},
                        primaryClass={cs.CV},
                        url={https://arxiv.org/abs/2307.00183}, 
                  }</code></pre>
                </div>
            </div>
        <br> We provide the VFN186 dataset, along with a novel framework that enhances generalization on long-tailed food distribution 
          using knowledge distillation and a CAM-CutMix-based augmentation technique.
      </div> 
  </div> 
</div>




      
<div style="margin-bottom: 3em;"> 
  <div class="row">
    <div class="col-sm-3">
      <img src="assets/img/projects/MadiMa_metafood_image_dist.png" class="img-fluid img-thumbnail" alt="Project image">
    </div>
        <div class="col-sm-9">
          <a style="font-weight: bold";>MFP3D: Monocular Food Portion Estimation Leveraging 3D Point Clouds (Oral)</a>
          <br>Jinge Ma, <span style="font-weight: bold";>Xiaoyan Zhang</span>, Gautham Vinod, Siddeshwar Raghavan, Jiangpeng He, Fengqing Zhu.
          <br><span style="font-style: italic;">International Conference on Pattern Recognition (ICPR) MADiMa workshop</span>, 2024
          <br><a href="https://arxiv.org/pdf/2411.10492" target="_blank">Paper</a>
<!--            / <a href="https://github.com/xiaoyuan1996/SemanticLocalizationMetrics" target="_blank">Code</a>  -->
          / <button class="btn btn-link" type="button" data-toggle="collapse" data-target="#collapsema2024mfp3d" aria-expanded="false" aria-controls="collapsema2024mfp3d" style="margin-left: -6px; margin-top: -2px;">Expand bibtex</button>
            
            <div class="collapse" id="collapsema2024mfp3d">
                <div class="card card-body">
                    <pre><code>@article{ma2024mfp3d,
                      title={MFP3D: Monocular Food Portion Estimation Leveraging 3D Point Clouds},
                      author={Ma, Jinge and Zhang, Xiaoyan and Vinod, Gautham and Raghavan, Siddeshwar and He, Jiangpeng and Zhu, Fengqing},
                      journal={arXiv preprint arXiv:2411.10492},
                      year={2024}
                  }</code></pre>
                </div>
            </div>    
        <br> We propose MFP3D, a new framework for accurate food portion estimation from a single image. It uses 3D reconstruction, feature extraction, 
          and deep learning to estimate food volume and energy content, showing improved accuracy on the MetaFood3D dataset compared to existing approaches.
      </div> 
  </div> 
</div>









      

 <!-- <div class="row" style="margin-top: 3em; margin-bottom: 1em;">
            <div class="col-sm-12" style="">
                <h4>Teaching Experience</h4>
                <ul>
                    <li><b>24 Fall: ZJ52014 Introduction to Artificial Intelligence</b>, <span style="font-style: italic;">Undergraduate Teaching Assistant</span> <span style="float: right;"> University</span></li>
                    <li><b>24 Fall: ZX52340 Java Technology and Its Application (Practice)</b>, <span style="font-style: italic;">Undergraduate Teaching Assistant</span> <span style="float: right;"> University</span></li>
      
                </ul>
            </div>
        </div> -->
      

<div class="row" style="margin-top: 3em; margin-bottom: 1em;">          
  <div class="col-sm-12" style="">
      <h4>Awards</h4>
      <ul>
        <li><b>Outstanding Graduate of Anhui Province</b>, <span style="font-style: italic;">Ministry of Education of Anhui Province</span> <span style="float: right;">2025</span></li>
        <li><b>Pacemaker to Merit Student</b>, <span style="font-style: italic;">Anhui University</span> <span style="float: right;">2022, 2023, 2024</span></li>
        <li><b>Merit Student</b>, <span style="font-style: italic;">Anhui University</span> <span style="float: right;">2022, 2023, 2024</span></li>
        <!--         <li><b>Honarable Mentioned</b> in the Interdisciplinary Contest in Modeling, <span style="font-style: italic;">The Consortium for Mathematics and Its Application</span> <span style="float: right;">2024</span></li>
        <li><b>Outstanding Mentioned</b> in the Second "Huashu Cup" International Mathematical Contest in Modeling, <span style="font-style: italic;">Big Data and Mathematical Modeling Committee of China Society for Future Studies</span> <span style="float: right;">2024</span></li> -->
        <li><b>Song Qingling Future Grant for Discipline Focus Students</b> (0.05%), <span style="font-style: italic;">The China Song Qingling Foundation</span> <span style="float: right;">2024</span></li>
        
        <li><b>Provincial Second Prize</b> in China Undergraduate Mathematical Contest in Modeling, <span style="font-style: italic;">China Society for Industrial and Applied Mathematics</span> <span style="float: right;">2024</span></li>
        <li><b>Excellent Student Scholarship</b>, <span style="font-style: italic;">Anhui University</span> <span style="float: right;">2023</span></li>
        <li><b>Academic Science and Technology Scholarship</b>, <span style="font-style: italic;">Anhui University</span> <span style="float: right;">2023</span></li>
<!--         <li><b>Pacemaker to Merit Student</b>, <span style="font-style: italic;">Anhui University</span> <span style="float: right;">2023</span></li> -->
<!--         <li><b>Merit Student</b>, <span style="font-style: italic;">Anhui University</span> <span style="float: right;">2023</span></li> -->
        <li><b>Provincial Silver Award</b> in China International College Studentsâ€™ Innovation Competition, <span style="font-style: italic;">Ministry of Education of Anhui Province</span> <span style="float: right;">2023</span></li>
<!--         <li><b>Pacemaker to Merit Student</b>, <span style="font-style: italic;">Anhui University</span> <span style="float: right;">2022</span></li> -->
<!--         <li><b>Merit Student</b>, <span style="font-style: italic;">Anhui University</span> <span style="float: right;">2022</span></li> -->
        
        

        
      </ul>
  </div>

  
</div>
      

      



       

        <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=cdc0b0&w=300&t=tt&d=XsaXIdSbwmNV33O0rzrWJ8b6Pj3KX4m36bLU7Nm9TKM&co=ffffff&cmn=6ca6cd&cmo=828282&ct=363636'></script>
    
    </div>

    <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js"
      integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN"
      crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js"
      integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q"
      crossorigin="anonymous"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js"
      integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl"
      crossorigin="anonymous"></script>
    <footer style="padding-left: 220px;">
        <p>Visitor Count since 22/09/2024. Thanks for the website template from <a href="https://m-niemeyer.github.io/" target="_blank">Michael Niemeyer</a>. Last updated on 01/10/2025<br>
        </p>
    </footer>
</body>

</html>
    
